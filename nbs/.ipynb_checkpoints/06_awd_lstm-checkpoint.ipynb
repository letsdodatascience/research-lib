{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from lib.nb_05 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/vks/.fastai/data/imdb')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/vks/.fastai/data/imdb/ld.pkl'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/test'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/ll_lm.pkl'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/vocab_lm.pkl'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/unsup'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/README'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/ll_clas.pkl'),\n",
       " PosixPath('/Users/vks/.fastai/data/imdb/train')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "il = TextList.from_files(path, extensions=\".txt\", include=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextList (100000 items)\n",
       "[PosixPath('/Users/vks/.fastai/data/imdb/test/neg/1821_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/9487_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/4604_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/2828_2.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/10890_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/3351_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/8070_2.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/1027_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/8248_3.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/4290_4.txt')...]\n",
       "Path: /Users/vks/.fastai/data/imdb"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: TextList (89945 items)\n",
       "[PosixPath('/Users/vks/.fastai/data/imdb/test/neg/4604_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/2828_2.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/10890_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/3351_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/8070_2.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/1027_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/10096_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/11890_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/2008_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/472_4.txt')...]\n",
       "Path: /Users/vks/.fastai/data/imdb\n",
       "Valid: TextList (10055 items)\n",
       "[PosixPath('/Users/vks/.fastai/data/imdb/test/neg/1821_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/9487_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/8248_3.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/4290_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/10131_3.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/1082_1.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/3439_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/12345_4.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/9149_3.txt'), PosixPath('/Users/vks/.fastai/data/imdb/test/neg/5932_1.txt')...]\n",
       "Path: /Users/vks/.fastai/data/imdb"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proc_tok, proc_num =  TokenizeProcessor(max_workers=8), NumericalizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='45' class='' max='45', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [45/45 04:30<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6/6 00:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll = label_by_func(sd, lambda y: 0, proc_x=[proc_tok, proc_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(ll, open(path/'ll_lm.pkl', 'wb'))\n",
    "# pickle.dump(proc_num.vocab, open(path/'vocab_lm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/'ll_lm.pkl', 'rb'))\n",
    "vocab = pickle.load(open(path/'vocab_lm.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs,bptt = 64,70\n",
    "data = lm_databunchify(ll, bs, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lib.nb_05.LM_PreLoader at 0x1a2f15b470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proc_num.vocab = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60003"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proc_num.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWD-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regularizing and Optimizing LSTM Language Models](https://arxiv.org/abs/1708.02182)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for lanfuage modelling : https://github.com/alvations/Quotables/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is important for the blog: https://elc.github.io/posts/embed-interactive-notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### LSTM from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"./images/LSTM.PNG\" alt=\"LSTM\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://forums.fast.ai/t/about-the-part-2-alumni-2018-category/13050/92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, ni, nh):\n",
    "        super().__init__()\n",
    "        self.ih = nn.Linear(ni, 4*nh)\n",
    "        self.hh = nn.Linear(nh, 4*nh)\n",
    "        \n",
    "    def forward(self, input, state):\n",
    "        h,c = state\n",
    "        #One big multiplication for all the gates is better than 4 smaller ones\n",
    "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1)\n",
    "        input_gate, forget_gate, output_gate = map(torch.sigmoid, gates[:3])\n",
    "        \n",
    "        cell_gate = gates[3].tanh()\n",
    "        c = (input_gate*cell_gate) + (forget_gate*c)\n",
    "        h = output_gate*(c.tanh())\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then we create a LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LSTMLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, cell, *cell_args):\n",
    "        super().__init__()\n",
    "        self.cell = cell(*cell_args)\n",
    "        \n",
    "    def forward(self, input, state):\n",
    "        inputs = input.unbind(1)\n",
    "        outputs = []\n",
    "        for i in range(len(inputs)):\n",
    "            out, state = self.cell(inputs[i], state)\n",
    "            outputs += [out]\n",
    "        return torch.stack(outputs, dim=1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm = LSTMLayer(LSTMCell, 300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(64, 70, 300)\n",
    "h = (torch.zeros(64, 300),torch.zeros(64, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y,h1 = lstm(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70, 300]), torch.Size([64, 300]), torch.Size([64, 300]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, h[0].shape, h[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70, 300]), torch.Size([64, 300]), torch.Size([64, 300]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, h1[0].shape, h1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 ms ± 7.94 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 y,h1 = lstm(x,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Builtin version in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(300, 300, 1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(64, 70, 300)\n",
    "h = (torch.zeros(1, 64, 300),torch.zeros(1, 64, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 ms ± 4.21 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 y,h1 = lstm(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??nn.LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1904.13310.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually apply dropout by drawing a mask which tells us which elements to nullify. First, we'll need all different kinds of dropouts. Dropout consists into replacing some coefficients by 0 with probability p. To ensure that the average of the weights remains constant, we apply a correction to the weights that aren't nullified of a factor `1/(1-p)` (think of what happens to the activations if you want to figure out why!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 1000)\n",
    "w = torch.randn(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.matmul(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 5]), tensor(-0.6854), tensor(31.8359))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape, o.mean(), o.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_mask(x, sz, p):\n",
    "    return x.new(*sz).bernoulli_(1-p).div_(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2., 2., 0., 2., 2., 2., 2., 0., 2.],\n",
       "        [0., 0., 2., 2., 2., 2., 0., 2., 2., 2.],\n",
       "        [0., 0., 0., 0., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 0., 0., 0., 2., 0., 2., 2., 2.],\n",
       "        [0., 2., 0., 2., 0., 0., 2., 0., 0., 2.],\n",
       "        [2., 2., 0., 0., 2., 0., 0., 2., 0., 0.],\n",
       "        [2., 0., 2., 0., 2., 0., 2., 2., 0., 0.],\n",
       "        [0., 2., 2., 0., 0., 2., 2., 2., 0., 2.],\n",
       "        [2., 0., 0., 2., 0., 2., 2., 0., 0., 2.],\n",
       "        [0., 0., 0., 2., 0., 2., 2., 2., 2., 0.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = dropout_mask(x, (10,10), 0.5); mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once with have a dropout mask `mask`, applying the dropout to `x` is simply done by `x = x * mask`. We create our own dropout mask and don't rely on pytorch dropout because we do not want to nullify all the coefficients randomly: on the sequence dimension, we will want to have always replace the same positions by zero along the seq_len dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.4703), tensor(1.0045))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x*mask).std(),x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmbeddingDropout applies dropout to full rows of the embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDropout(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb, emb_p):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb, self.emb_p = emb, emb_p\n",
    "        \n",
    "        self.pad_idx = self.emb.padding_idx\n",
    "        if self.pad_idx is None: self.pad_idx = -1\n",
    "            \n",
    "    def forward(self, words, scale=None):\n",
    "        \n",
    "        if self.training and self.emb_p != 0:\n",
    "            size = (self.emb.weight.size(0),1)\n",
    "            mask = dropout_mask(self.emb.weight.data, size, self.emb_p)\n",
    "            masked_embed = self.emb.weight * mask\n",
    "        else: masked_embed = self.emb.weight\n",
    "        \n",
    "        if scale: masked_embed.mul_(scale)\n",
    "        \n",
    "        return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n",
    "                           self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2233, -3.7516, -3.2776, -1.2085,  2.9653,  0.3546,  1.2977],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0977, -1.1382,  0.8102,  2.2662, -0.1504, -1.0847,  1.0047],\n",
       "        [-0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [ 1.2233, -3.7516, -3.2776, -1.2085,  2.9653,  0.3546,  1.2977],\n",
       "        [-0.5515, -0.7580, -0.0680,  1.5561, -4.5838, -4.5542, -1.6144],\n",
       "        [-0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = nn.Embedding(100, 7, padding_idx=1)\n",
    "enc_dp = EmbeddingDropout(enc, 0.5)\n",
    "tst_input = torch.randint(0,100,(8,))\n",
    "enc_dp(tst_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WeightDropout` is dropout applied to the weights of the inner LSTM hidden to hidden matrix. This is a little hacky if we want to preserve the CuDNN speed and not reimplement the cell from scratch. We add a parameter that will contain the raw weights, and we replace the weight matrix in the LSTM at the beginning of the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_HH = 'weight_hh_l0'\n",
    "\n",
    "class WeightDropout(nn.Module):\n",
    "    \n",
    "    def __init__(self, module, weight_p=[0.], layer_names=[WEIGHT_HH]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.module, self.weight_p, self.layer_names = module, weight_p, layer_names\n",
    "        \n",
    "        for layer in self.layer_names: \n",
    "            #Makes a copy of the weights of the selected layers.\n",
    "            w = getattr(self.module, layer)\n",
    "            print(w.shape)\n",
    "            self.register_parameter(f\"{layer}_raw\", nn.Parameter(w.data))\n",
    "            self._parameters[layer] = F.dropout(w, p=self.weight_p, training=False)\n",
    "            \n",
    "    def _set_weights(self):\n",
    "        for layer in self.layer_names:\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "            self.module._parameters[layer] = F.dropout(raw_w, p=self.weight_p, training=self.training)\n",
    "            \n",
    "    def forward(self, *args):\n",
    "        self._set_weights()\n",
    "        with warnings.catch_warnings():\n",
    "            #To avoid the warning that comes because the weights aren't flattened.\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0361,  0.3543],\n",
       "        [ 0.6720,  0.4424],\n",
       "        [-0.2037, -0.3487],\n",
       "        [ 0.1967, -0.5188],\n",
       "        [-0.2932,  0.1156],\n",
       "        [ 0.5947, -0.4185],\n",
       "        [ 0.3082,  0.0745],\n",
       "        [-0.2223, -0.4125]], requires_grad=True)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(5, 2)\n",
    "dp_module = WeightDropout(module, 0.7)\n",
    "getattr(dp_module.module, WEIGHT_HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 1.2723, -2.1636],\n",
       "        [-0.0181, -0.0000],\n",
       "        [-0.0000,  0.0000],\n",
       "        [ 0.0000,  0.2398]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_input = torch.randn(4,20,5)\n",
    "h = (torch.zeros(1,20,2), torch.zeros(1,20,2))\n",
    "x,h = dp_module(tst_input,h)\n",
    "getattr(dp_module.module, WEIGHT_HH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside a RNN, a tensor `x` will have three dimensions: `bs, seq_len, vocab_size`.  Recall that **we want to consistently apply the dropout mask across the seq_len dimension**, therefore, *we create a dropout mask for the first and third dimension and broadcast it to the seq_len dimension*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RNNDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p == 0.: return x\n",
    "        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n",
    "        return x * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.7715,  0.6726,  2.4034, -0.3766],\n",
       "          [ 0.1787, -1.0251,  0.6849, -0.6132],\n",
       "          [-0.2798,  0.1683, -0.1621, -0.9038]],\n",
       " \n",
       "         [[ 1.0908, -1.5989,  0.0769, -0.1853],\n",
       "          [-0.8224,  0.8488,  1.1800, -0.0656],\n",
       "          [ 0.8933, -0.1234,  0.0147,  0.1530]],\n",
       " \n",
       "         [[ 0.6616, -0.1280, -0.3851, -0.6454],\n",
       "          [ 0.2131,  0.0857, -2.3901, -1.1107],\n",
       "          [ 1.5511, -0.4287,  0.9462, -0.9746]]]),\n",
       " tensor([[[ 1.1021,  0.0000,  3.4334, -0.5380],\n",
       "          [ 0.2553, -0.0000,  0.9785, -0.8760],\n",
       "          [-0.3997,  0.0000, -0.2316, -1.2911]],\n",
       " \n",
       "         [[ 0.0000, -2.2841,  0.1098, -0.2647],\n",
       "          [-0.0000,  1.2125,  1.6857, -0.0936],\n",
       "          [ 0.0000, -0.1763,  0.0210,  0.2186]],\n",
       " \n",
       "         [[ 0.9451, -0.1829, -0.5501, -0.9220],\n",
       "          [ 0.3044,  0.1225, -3.4144, -1.5867],\n",
       "          [ 2.2158, -0.6124,  1.3517, -1.3922]]]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = RNNDropout(0.3)\n",
    "tst_input = torch.randn(3,3,4)\n",
    "tst_input, dp(tst_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_detach(h):\n",
    "    \"Detaches `h` from its history.\"\n",
    "    return h.detach() if type(h) == torch.Tensor else tuple(to_detach(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWD_LSTM(nn.Module):\n",
    "    \"AWD-LSTM inspired by https://arxiv.org/abs/1708.02182.\"\n",
    "\n",
    "    initrange=0.1\n",
    "    \n",
    "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_tok,\n",
    "                hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bs, self.emb_sz, self.n_hid, self.n_layers = 1, emb_sz, n_hid, n_layers\n",
    "        #Embedding and Embedding Dropout\n",
    "        self.emb = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_tok)\n",
    "        self.emb_dp = EmbeddingDropout(self.emb, embed_p)\n",
    "        self.emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        \n",
    "        ## RNN and Weight Dropout\n",
    "        self.rnns = [nn.LSTM(self.emb_sz if l == 0 else self.n_hid,\n",
    "                             (n_hid if l != n_layers - 1 else emb_sz),\n",
    "                             batch_first=True) for l in range(self.n_layers)]\n",
    "        self.rnns = nn.ModuleList([WeightDropout(rnn, weight_p) for rnn in self.rnns])\n",
    "        \n",
    "        ##Input anf HH Drpoouts\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in self.n_layers])\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        bs,sl = input.size()\n",
    "        ## takes care of the last batch and the first, getting a new hidden state ?? \n",
    "        if bs!=self.bs:\n",
    "            self.bs = bs \n",
    "            self.reset()\n",
    "            \n",
    "        raw_output = self.input_dp(self.emb_dp(input))\n",
    "        \n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        \n",
    "        # we do this because we are not using built in LSTM n_layers\n",
    "        # the reason being, we want to add dropout\n",
    "        # does this introduce timing delays ?? \n",
    "        for l, (rnn, hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l]) # where is this self.hidden coming from ? \n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output) \n",
    "            \n",
    "        self.hidden = to_detach(new_hidden)\n",
    "        \n",
    "        return raw_outputs, outputs\n",
    "    \n",
    "    def _one_hidden(self, l):\n",
    "        \"Return one hidden state.\"\n",
    "        nh = self.n_hid if l != self.n_layers - 1 else self.emb_sz\n",
    "        return next(self.parameters()).new(1, self.bs, nh).zero_()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the hidden states\"\"\"\n",
    "        self.hidden = [(self._one_hidden(l), self._one_hidden(l)) for l in range(self.n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-fastai",
   "language": "python",
   "name": "my-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
