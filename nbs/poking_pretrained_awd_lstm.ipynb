{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from lib.nb_06 import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/pretrained_lm/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/pretrained_lm/ll_wiki.pkl'),\n",
       " PosixPath('../data/pretrained_lm/pretrained.pth'),\n",
       " PosixPath('../data/pretrained_lm/vocab.pkl')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/\"ll_wiki.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open(path/'vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 60002)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ll.train.proc_x[-1].vocab), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18417, 60)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ll.train), len(ll.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, bptt = 128, 70\n",
    "data = lm_databunchify(ll, bs, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.1, 0.15, 0.25, 0.02, 0.2]) * 0.2\n",
    "tok_pad = vocab.index(PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sz, nh, nl = 300, 300, 2\n",
    "model = get_awd_lstm_language_model(len(vocab), emb_sz, nh, nl, tok_pad, *dps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [partial(AvgStatsCallback,accuracy_flat),\n",
    "       partial(CudaCallback, get_device()), \n",
    "       Recorder,\n",
    "       partial(GradientClipping, clip=0.1),\n",
    "       partial(RNNTrainer, α=2., β=1.),\n",
    "       ProgressCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, data, cross_entropy_flat, lr=5e-3, cb_funcs=cbs, opt_func=adam_opt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.load_state_dict(torch.load(path/\"pretrained.pth\", map_location=get_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (emb): Embedding(60002, 300, padding_idx=1)\n",
       "    (emb_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60002, 300, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(300, 300, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(300, 300, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (output_dp): RNNDropout()\n",
       "    (decoder): Linear(in_features=300, out_features=60002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and make one step ahead predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = \"once upon a time \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'once upon a time '"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TokenizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['xxbos', 'once', 'upon', 'a', 'time', 'xxeos']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp([test_sent, test_sent])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numercalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2, 442, 433, 15, 69]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.train.proc_x[-1].proc1(tp([test_sent])[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_test_sent = ll.train.proc_x[-1].proc1(tp([test_sent])[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.stack((torch.tensor(num_test_sent),torch.tensor(num_test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2, 442, 433,  15,  69],\n",
       "        [  2, 442, 433,  15,  69]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    outs = learn.model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded, raw_outputs, outputs = outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoded tensor is flattened to `bs * seq_len` by `len(vocab)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, sl = inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 60002])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`raw_outputs` and `outputs` each contain the results of the intermediary layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_outputs), len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([2, 5, 300]), torch.Size([2, 5, 300])],\n",
       " [torch.Size([2, 5, 300]), torch.Size([2, 5, 300])])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.size() for o in raw_outputs], [o.size() for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = decoded.view(bs, sl, -1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tok = torch.argmax(F.softmax(pred_1[-1], dim=0))#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[pred_tok.item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we need to append pred_tok to inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = inp.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_sent = np.append(inp1 , np.array([pred_tok.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.stack((torch.tensor(num_test_sent),torch.tensor(num_test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2, 442, 433,  15,  69,  11],\n",
       "        [  2, 442, 433,  15,  69,  11]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_tok(num_test_sent):\n",
    "    inp = torch.stack((torch.tensor(num_test_sent),torch.tensor(num_test_sent)))\n",
    "    bs, sl = inp.shape\n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        outs = learn.model(inp)\n",
    "    decoded, raw_outputs, outputs = outs\n",
    "    \n",
    "    pred_1 = decoded.view(bs, sl, -1)[0]\n",
    "    pred_tok = torch.argmax(F.softmax(pred_1[-1], dim=0))\n",
    "    return pred_tok.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(learn, test_sent, vocab = vocab, num_toks=50):\n",
    "    num_test_sent = ll.train.proc_x[-1].proc1(tp([test_sent])[0][:-1])\n",
    "    \n",
    "    for i in range(num_toks):\n",
    "        next_tok = get_next_tok(num_test_sent)\n",
    "        num_test_sent = np.append(num_test_sent , np.array([next_tok]))\n",
    "    \n",
    "    text = [vocab[tok] for tok in num_test_sent]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'xxbos due to low - level xxmaj canadian xxmaj american ancestry , the xxmaj united xxmaj states xxmaj army ( xxmaj army ) , xxmaj united xxmaj states xxmaj army ( xxmaj army ) , xxmaj united xxmaj states xxmaj army ( xxmaj army ) , xxmaj united xxmaj states xxmaj army ( xxmaj'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(learn, \"due to low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top k sampling and neucleus sampling, shamelessly copied from [this twitter thread](https://twitter.com/thom_wolf/status/1124263846674345985?s=12) by Thomas Wold of Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some research pointers:\n",
    "- [Importance of a Search Strategy in Neural Dialogue Modelling](https://arxiv.org/pdf/1811.00907.pdf)\n",
    "- [Correcting Length Bias in Neural Machine Translation](https://arxiv.org/abs/1808.10006)\n",
    "- [Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation](https://arxiv.org/abs/1808.09582)\n",
    "- [Hierarchical Neural Story Generation](https://arxiv.org/abs/1805.04833)\n",
    "- [Better Language Models and Their Implications](https://openai.com/blog/better-language-models/)\n",
    "- [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Today, the most promising candidates for high-entropy tasks decoders seem to be top-k & nucleus sampling\n",
    "General principle: at each step, sample from the next-token distribution filtered to keep only the top-k tokens or the top tokens with cumulative prob above a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (..., vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "    \"\"\"\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TokenizeProcessor()\n",
    "test_sent = \"once upon a time, \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_test_sent = ll.train.proc_x[-1].proc1(tp([test_sent])[0][:-1])\n",
    "inp = torch.stack((torch.tensor(num_test_sent),torch.tensor(num_test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    outs = learn.model(inp)\n",
    "\n",
    "decoded, raw_outputs, outputs = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how to use this function for top-p sampling\n",
    "temperature = 1.0\n",
    "top_k = 0\n",
    "top_p = 0.9\n",
    "\n",
    "# Get logits with a forward pass in our model (input is pre-defined)\n",
    "#logits = model(input)\n",
    "\n",
    "# Keep only the last token predictions, apply a temperature coefficient and filter\n",
    "logits = logits[..., -1, :] / temperature\n",
    "filtered_logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "\n",
    "# Sample from the filtered distribution\n",
    "probabilities = F.softmax(filtered_logits, dim=-1)\n",
    "next_token = torch.multinomial(probabilities, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2036])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joint'"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[next_token.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_tok_sample(logits, top_k=0, top_p=0.9, tempreature=1.0):\n",
    "    # Keep only the last token predictions, apply a temperature coefficient and filter\n",
    "    logits = logits[..., -1, :].clone().detach() / temperature\n",
    "    filtered_logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "\n",
    "    # Sample from the filtered distribution\n",
    "    probabilities = F.softmax(filtered_logits, dim=-1)\n",
    "    next_token = torch.multinomial(probabilities, 1)\n",
    "    return next_token.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(learn, num_test_sent):\n",
    "    #print(num_test_sent)\n",
    "    inp = torch.stack((torch.tensor(num_test_sent),torch.tensor(num_test_sent)))\n",
    "    #print(inp.shape)\n",
    "    #bs, sl = inp.shape\n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        outs = learn.model(inp)\n",
    "    decoded, raw_outputs, outputs = outs\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(learn, test_sent, vocab = vocab, num_toks=50):\n",
    "    num_test_sent = ll.train.proc_x[-1].proc1(tp([test_sent])[0][:-1])\n",
    "    for i in range(num_toks):\n",
    "        logits = get_logits(learn, num_test_sent)\n",
    "        next_tok = get_next_tok_sample(logits)\n",
    "        num_test_sent = np.append(num_test_sent , np.array([next_tok]))\n",
    "    \n",
    "    text = [vocab[tok] for tok in num_test_sent]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'xxbos once upon a time , there are several tribal bands associated with the xxmaj middle xxmaj east . xxmaj the original for a settlement is on the corner of xxmaj hale and xxmaj lowry xxmaj road , and began a productive modification of a school built during the early stages of the boom . xxmaj the'"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(learn, \"once upon a time, there\", vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'xxbos once upon a time , there were several variations between attitudes to students , who eventually had learned over the political spectrum , and their inspirations : and the younger sense of interest in the xxmaj western house was broken up in favor of planning to explore separate \" treasure \" models of the original . xxmaj when xxmaj guests chose to stay with xxmaj gertrude , she produced the photographs for the xxmaj queen \\'s and xxmaj albert xxmaj park xxmaj row standards ; however , xxmaj jacqueline knew that xxmaj miss xxmaj lee , though uncertain about the connection , wanted to win by'"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(learn, \"once upon a time, there\", vocab=vocab, num_toks=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj there is a strong chance of acquiring information that takes the information on the earth and asserts that most land upon which it can not be read by the individual have been encouraged , and the level has been governed by the short , more extensive term that was in full development . xxmaj others argue that news can not be obtained , while xxmaj ancient xxmaj histories , today how scholars discuss the a language of material which had broken down , would have created a stable definition for the economy . xxmaj this theory gives rise to xxmaj christian beliefs in a xxmaj history of xxmaj absolute xxmaj change , xxmaj questions , and the tradition of history of every city . xxmaj within the xxmaj eighteenth xxmaj century , a true study of the present nation was carried by the director of the social law system , the xxmaj people \\'s xxmaj republic of xxmaj ireland xxmaj who , which \" took some jobs \" for several organizations . xxmaj new figure of xxmaj alice \\'s youth used the term xxmaj mary xxmaj poppins . xxmaj the game was released in 1997 in a hardback set as xxmaj james xxmaj xxunk \\'s xxmaj science and xxmaj journalism xxmaj festival in xxmaj cardiff in xxmaj sydney , xxmaj england . xxmaj the new adult scores xxmaj winning xxmaj laws and xxmaj provisions xxmaj press , with xxmaj jervis \\' xxmaj happiness , are the most important science fiction associated with the field , and the book remains only a copy of the case , so they eventually start xxmaj beagle the door to another candidate for the side , so his ideas are rejected . \\n \\n  = = xxmaj pre - production = = \\n \\n  xxmaj in xxmaj november 2009 , xxmaj clyde xxmaj bain xxmaj entertainment created a new production film . xxmaj it featured footage of xxmaj jonathan and xxmaj newell , involving the first presumed to be possible . xxmaj as far away as her character , it is likely that xxmaj carlton \\'s method was set to avoid editing . \\n  xxmaj it was screened at the xxmaj academy xxmaj award for xxmaj best xxmaj screenplay and xxmaj favorite xxmaj actor at the xxmaj british xxmaj academy for xxmaj film in the industry . xxmaj roger xxmaj xxunk received word of the film in xxmaj march 2008 , where he bought two more factories and presented xxmaj harry xxmaj jacks ( an audio test machine in xxmaj chichester , d.c. ) . xxmaj care to xxmaj supply was seen as xxunk if anything could be done . \\n  xxmaj of these , xxmaj aaron xxmaj xxunk \\'s set of thirteen shots of the film film – two with xxmaj xxunk ( \" xxmaj homework \" ) is its first release . xxmaj the second , titled xxmaj save xxmaj kill xxmaj me : xxmaj my xxmaj life , is an adaptation of the xxmaj duke of xxmaj hippo to'"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(learn, \"There is a strong chance\", vocab=vocab, num_toks=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-fastai",
   "language": "python",
   "name": "my-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
