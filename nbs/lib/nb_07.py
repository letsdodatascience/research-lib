
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/07_admin_callbacks.ipynb

from lib.nb_06 import *

class TerminateOnNaNCallback(Callback):
    "A `Callback` that terminates training if loss is NaN."
    def __init__(self):
        self.last_loss=np.inf

    def after_loss(self):

        if(torch.isnan(self.loss)):
            print("Loss of current batch NaN, Stopping")
            print(f"Loss for last Batch is {self.last_loss}")
            raise CancelTrainException()

        self.last_loss = self.loss

class TrackerCallback(Callback):
    "A `Callback` that keeps track of the best value in `monitor`."

    def __init__(self, monitor:str='valid_loss', mode="auto"):
        super().__init__()
        self.monitor,self.mode = monitor,mode
        if self.mode not in ['auto', 'min', 'max']:
            warnings.warn(f'{self.__class__} mode {self.mode} is invalid, falling back to "auto" mode.')
            self.mode = 'auto'
        mode_dict = {'min': np.less, 'max':np.greater}
        mode_dict['auto'] = np.less if 'loss' in self.monitor else np.greater
        self.operator = mode_dict[self.mode]

    def begin_fit(self):
        "Initializes the best value."
        self.best = float('inf') if self.operator == np.less else -float('inf')

    def get_monitor_value(self):
        "Pick the monitored value."
        values = {"train_loss": self.run.avg_stats.train_stats.avg_stats[0],
                  "valid_loss": self.run.avg_stats.valid_stats.avg_stats[0]}

        if values.get(self.monitor) is None:
            warnings.warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available.')

        return values.get(self.monitor)

class SaveModelCallback(TrackerCallback):
    "A `TrackerCallback` that saves the model when monitored quantity is best."

    _order = 10000 ##probably this needs to be the last cb that is invoked

    def __init__(self, savename = "test_cb", monitor:str='valid_loss', mode:str='auto',
                 every:str='improvement', name:str='bestmodel'):

        super().__init__(monitor=monitor, mode=mode)

        self.every, self.best_epoch = every, 0
        if self.every not in ['improvement', 'epoch']:
            warnings.warn(f'SaveModel every {self.every} is invalid, falling back to "improvement".')
            self.every = 'improvement'

        self.save_path = Path(f"./models/{savename}")
        os.makedirs(self.save_path, exist_ok=True)


    def after_epoch(self):
        "Compare the value monitored to its best score and maybe save the model."
        if self.every=="epoch":
            torch.save(self.run.model.state_dict(),
                       f'{self.save_path}/epoch:{self.epoch}_{self.get_monitor_value()}.pth')
        else: #every="improvement"
            current = self.get_monitor_value()
            if current is not None and self.operator(current, self.best):
                print(f'Better model found at epoch {self.epoch} with {self.monitor} value: {current}.')
                self.best = current
                self.best_epoch = self.epoch
                torch.save(self.run.model.state_dict(),
                           f'{self.save_path}/epoch:{self.epoch}_{self.best}.pth')


    def after_fit(self):
        "Load the best model."
        if self.every == "improvement":
            self.run.model.load_state_dict(torch.load(f'{self.save_path}/epoch:{self.best_epoch}_{self.best}.pth'))
            print(f"Loaded the best model found at Epoch:{self.best_epoch}")
